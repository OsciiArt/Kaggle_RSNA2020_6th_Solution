{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob, pickle, time, gc, copy, sys\n",
    "import warnings\n",
    "import cv2\n",
    "import multiprocessing\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sys.path.append('../src')\n",
    "from utils import ri, pickle_load, pickle_save\n",
    "from preprocess_fold import data_split_StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from sklearn import metrics\n",
    "import timm\n",
    "from utils_pytorch import cycle, CosineLR, AverageMeter\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose,\n",
    "    RandomCrop,\n",
    "    RandomBrightnessContrast,\n",
    "    ShiftScaleRotate,\n",
    "    Cutout,\n",
    ")\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "DEBUG = True # set False to do all process\n",
    "preprocess_dir = \"../input/preprocess\"\n",
    "output_path = \"../output\"\n",
    "df_train_path = \"{}/df_train.csv\".format(preprocess_dir)\n",
    "train_npy_dir_path = \"{}/train_law_npy\".format(preprocess_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLD = 5\n",
    "NUM_EPOCH = 16\n",
    "NUM_CYCLE = 16\n",
    "BATCH_SIZE = 80\n",
    "FOLD_LIST = [1,2,3,4,5] \n",
    "LR_RANGE = [1e-3, 1e-4]\n",
    "STEP_PER_EPOCH = 512\n",
    "REDUCE_RATE = 0.1\n",
    "MODEL_NAME = 'b0' # b0 or b2\n",
    "if DEBUG:\n",
    "    NUM_EPOCH = 1\n",
    "    NUM_CYCLE = 1\n",
    "    FOLD_LIST = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_CLASS: 10\n"
     ]
    }
   ],
   "source": [
    "col_index = 'SOPInstanceUID'\n",
    "col_groupby = 'StudyInstanceUID'\n",
    "col_targets = [\n",
    "    'negative_exam_for_pe',\n",
    "    'indeterminate',\n",
    "    'chronic_pe',\n",
    "    'acute_and_chronic_pe',\n",
    "    'central_pe',\n",
    "    'leftsided_pe',\n",
    "    'rightsided_pe',\n",
    "    'rv_lv_ratio_gte_1',\n",
    "    'rv_lv_ratio_lt_1',\n",
    "    'pe_present_on_image',\n",
    "]\n",
    "NUM_CLASS = len(col_targets)\n",
    "print('NUM_CLASS: {}'.format(NUM_CLASS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1790594, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>pe_present_on_image</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>qa_motion</th>\n",
       "      <th>qa_contrast</th>\n",
       "      <th>flow_artifact</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>rv_lv_ratio_lt_1</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>chronic_pe</th>\n",
       "      <th>true_filling_defect_not_pe</th>\n",
       "      <th>rightsided_pe</th>\n",
       "      <th>acute_and_chronic_pe</th>\n",
       "      <th>central_pe</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>dicom_path</th>\n",
       "      <th>RescaleSlope</th>\n",
       "      <th>RescaleIntercept</th>\n",
       "      <th>PatientPosition</th>\n",
       "      <th>series_index</th>\n",
       "      <th>num_series</th>\n",
       "      <th>m_i</th>\n",
       "      <th>q_i</th>\n",
       "      <th>npy_path</th>\n",
       "      <th>exam_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>baedb900c69c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>/mnt/disks/data6/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>52b6b0b793bb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>/mnt/disks/data6/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>1997c99c9d59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>/mnt/disks/data6/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>c6f29ac6659b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>3.0</td>\n",
       "      <td>124</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>/mnt/disks/data6/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>487d9ab5531f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>/mnt/disks/data6/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StudyInstanceUID SeriesInstanceUID SOPInstanceUID  pe_present_on_image  \\\n",
       "0     6897fa9de148      2bfbb7fd2e8b   baedb900c69c                  0.0   \n",
       "1     6897fa9de148      2bfbb7fd2e8b   52b6b0b793bb                  0.0   \n",
       "2     6897fa9de148      2bfbb7fd2e8b   1997c99c9d59                  0.0   \n",
       "3     6897fa9de148      2bfbb7fd2e8b   c6f29ac6659b                  0.0   \n",
       "4     6897fa9de148      2bfbb7fd2e8b   487d9ab5531f                  0.0   \n",
       "\n",
       "   negative_exam_for_pe  qa_motion  qa_contrast  flow_artifact  \\\n",
       "0                   0.0        0.0          0.0            0.0   \n",
       "1                   0.0        0.0          0.0            0.0   \n",
       "2                   0.0        0.0          0.0            0.0   \n",
       "3                   0.0        0.0          0.0            0.0   \n",
       "4                   0.0        0.0          0.0            0.0   \n",
       "\n",
       "   rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  leftsided_pe  chronic_pe  \\\n",
       "0                0.0               1.0           1.0         0.0   \n",
       "1                0.0               1.0           1.0         0.0   \n",
       "2                0.0               1.0           1.0         0.0   \n",
       "3                0.0               1.0           1.0         0.0   \n",
       "4                0.0               1.0           1.0         0.0   \n",
       "\n",
       "   true_filling_defect_not_pe  rightsided_pe  acute_and_chronic_pe  \\\n",
       "0                         0.0            1.0                   0.0   \n",
       "1                         0.0            1.0                   0.0   \n",
       "2                         0.0            1.0                   0.0   \n",
       "3                         0.0            1.0                   0.0   \n",
       "4                         0.0            1.0                   0.0   \n",
       "\n",
       "   central_pe  indeterminate  \\\n",
       "0         0.0            0.0   \n",
       "1         0.0            0.0   \n",
       "2         0.0            0.0   \n",
       "3         0.0            0.0   \n",
       "4         0.0            0.0   \n",
       "\n",
       "                                          dicom_path  RescaleSlope  \\\n",
       "0  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "1  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "2  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "3  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "4  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "\n",
       "   RescaleIntercept PatientPosition  series_index  num_series   m_i      q_i  \\\n",
       "0           -1024.0             HFS           0.0         124  42.0  0.33871   \n",
       "1           -1024.0             HFS           1.0         124  42.0  0.33871   \n",
       "2           -1024.0             HFS           2.0         124  42.0  0.33871   \n",
       "3           -1024.0             HFS           3.0         124  42.0  0.33871   \n",
       "4           -1024.0             HFS           4.0         124  42.0  0.33871   \n",
       "\n",
       "                                            npy_path  exam_index  \n",
       "0  /mnt/disks/data6/rsna2020/preprocessed/train_l...           0  \n",
       "1  /mnt/disks/data6/rsna2020/preprocessed/train_l...           0  \n",
       "2  /mnt/disks/data6/rsna2020/preprocessed/train_l...           0  \n",
       "3  /mnt/disks/data6/rsna2020/preprocessed/train_l...           0  \n",
       "4  /mnt/disks/data6/rsna2020/preprocessed/train_l...           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load train data\n",
    "df_train = pd.read_csv(df_train_path)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7279, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>pe_present_on_image</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>qa_motion</th>\n",
       "      <th>qa_contrast</th>\n",
       "      <th>flow_artifact</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>rv_lv_ratio_lt_1</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>chronic_pe</th>\n",
       "      <th>true_filling_defect_not_pe</th>\n",
       "      <th>rightsided_pe</th>\n",
       "      <th>acute_and_chronic_pe</th>\n",
       "      <th>central_pe</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>dicom_path</th>\n",
       "      <th>RescaleSlope</th>\n",
       "      <th>RescaleIntercept</th>\n",
       "      <th>PatientPosition</th>\n",
       "      <th>series_index</th>\n",
       "      <th>num_series</th>\n",
       "      <th>m_i</th>\n",
       "      <th>q_i</th>\n",
       "      <th>npy_path</th>\n",
       "      <th>exam_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>baedb900c69c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>/mnt/disks/data6/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>013358b540bb</td>\n",
       "      <td>2805267980e7</td>\n",
       "      <td>c0e16bbe96ef</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>/mnt/disks/data6/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0cee26703028</td>\n",
       "      <td>bac7becd2970</td>\n",
       "      <td>64bf37f1a302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.118056</td>\n",
       "      <td>/mnt/disks/data6/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c28f3d01b14f</td>\n",
       "      <td>7d17c72fd0ce</td>\n",
       "      <td>265035a0f7aa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>/mnt/disks/data6/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c8fbf1e08ac5</td>\n",
       "      <td>275497911f02</td>\n",
       "      <td>7a33bbba8386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>/mnt/disks/data6/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StudyInstanceUID SeriesInstanceUID SOPInstanceUID  pe_present_on_image  \\\n",
       "0     6897fa9de148      2bfbb7fd2e8b   baedb900c69c                  0.0   \n",
       "1     013358b540bb      2805267980e7   c0e16bbe96ef                  0.0   \n",
       "2     0cee26703028      bac7becd2970   64bf37f1a302                  0.0   \n",
       "3     c28f3d01b14f      7d17c72fd0ce   265035a0f7aa                  0.0   \n",
       "4     c8fbf1e08ac5      275497911f02   7a33bbba8386                  0.0   \n",
       "\n",
       "   negative_exam_for_pe  qa_motion  qa_contrast  flow_artifact  \\\n",
       "0                   0.0        0.0          0.0            0.0   \n",
       "1                   1.0        0.0          0.0            0.0   \n",
       "2                   0.0        0.0          0.0            0.0   \n",
       "3                   0.0        0.0          0.0            0.0   \n",
       "4                   1.0        0.0          0.0            0.0   \n",
       "\n",
       "   rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  leftsided_pe  chronic_pe  \\\n",
       "0                0.0               1.0           1.0         0.0   \n",
       "1                0.0               0.0           0.0         0.0   \n",
       "2                0.0               1.0           0.0         1.0   \n",
       "3                0.0               1.0           1.0         0.0   \n",
       "4                0.0               0.0           0.0         0.0   \n",
       "\n",
       "   true_filling_defect_not_pe  rightsided_pe  acute_and_chronic_pe  \\\n",
       "0                         0.0            1.0                   0.0   \n",
       "1                         0.0            0.0                   0.0   \n",
       "2                         0.0            1.0                   0.0   \n",
       "3                         0.0            0.0                   0.0   \n",
       "4                         0.0            0.0                   0.0   \n",
       "\n",
       "   central_pe  indeterminate  \\\n",
       "0         0.0            0.0   \n",
       "1         0.0            0.0   \n",
       "2         0.0            0.0   \n",
       "3         0.0            0.0   \n",
       "4         0.0            0.0   \n",
       "\n",
       "                                          dicom_path  RescaleSlope  \\\n",
       "0  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "1  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "2  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "3  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "4  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "\n",
       "   RescaleIntercept PatientPosition  series_index  num_series   m_i       q_i  \\\n",
       "0           -1024.0             HFS           0.0         124  42.0  0.338710   \n",
       "1           -1024.0             HFS           0.0         145   0.0  0.000000   \n",
       "2           -1024.0             HFS           0.0         144  17.0  0.118056   \n",
       "3           -1024.0             HFS           0.0         105   6.0  0.057143   \n",
       "4           -1024.0             HFS           0.0          81   0.0  0.000000   \n",
       "\n",
       "                                            npy_path  exam_index  \n",
       "0  /mnt/disks/data6/rsna2020/preprocessed/train_l...           0  \n",
       "1  /mnt/disks/data6/rsna2020/preprocessed/train_l...           1  \n",
       "2  /mnt/disks/data6/rsna2020/preprocessed/train_l...           2  \n",
       "3  /mnt/disks/data6/rsna2020/preprocessed/train_l...           3  \n",
       "4  /mnt/disks/data6/rsna2020/preprocessed/train_l...           4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make exam-level train data\n",
    "df_train_exam = ri(df_train[df_train[col_groupby].duplicated()==False])\n",
    "print(df_train_exam.shape)\n",
    "df_train_exam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disks/data4/rsna2020/preprocessed/train_law_npy/baedb900c69c.npy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>pe_present_on_image</th>\n",
       "      <th>negative_exam_for_pe</th>\n",
       "      <th>qa_motion</th>\n",
       "      <th>qa_contrast</th>\n",
       "      <th>flow_artifact</th>\n",
       "      <th>rv_lv_ratio_gte_1</th>\n",
       "      <th>rv_lv_ratio_lt_1</th>\n",
       "      <th>leftsided_pe</th>\n",
       "      <th>chronic_pe</th>\n",
       "      <th>true_filling_defect_not_pe</th>\n",
       "      <th>rightsided_pe</th>\n",
       "      <th>acute_and_chronic_pe</th>\n",
       "      <th>central_pe</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>dicom_path</th>\n",
       "      <th>RescaleSlope</th>\n",
       "      <th>RescaleIntercept</th>\n",
       "      <th>PatientPosition</th>\n",
       "      <th>series_index</th>\n",
       "      <th>num_series</th>\n",
       "      <th>m_i</th>\n",
       "      <th>q_i</th>\n",
       "      <th>npy_path</th>\n",
       "      <th>exam_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>baedb900c69c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>52b6b0b793bb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>1997c99c9d59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>c6f29ac6659b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>3.0</td>\n",
       "      <td>124</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>2bfbb7fd2e8b</td>\n",
       "      <td>487d9ab5531f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train-j...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>HFS</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.33871</td>\n",
       "      <td>/mnt/disks/data4/rsna2020/preprocessed/train_l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StudyInstanceUID SeriesInstanceUID SOPInstanceUID  pe_present_on_image  \\\n",
       "0     6897fa9de148      2bfbb7fd2e8b   baedb900c69c                  0.0   \n",
       "1     6897fa9de148      2bfbb7fd2e8b   52b6b0b793bb                  0.0   \n",
       "2     6897fa9de148      2bfbb7fd2e8b   1997c99c9d59                  0.0   \n",
       "3     6897fa9de148      2bfbb7fd2e8b   c6f29ac6659b                  0.0   \n",
       "4     6897fa9de148      2bfbb7fd2e8b   487d9ab5531f                  0.0   \n",
       "\n",
       "   negative_exam_for_pe  qa_motion  qa_contrast  flow_artifact  \\\n",
       "0                   0.0        0.0          0.0            0.0   \n",
       "1                   0.0        0.0          0.0            0.0   \n",
       "2                   0.0        0.0          0.0            0.0   \n",
       "3                   0.0        0.0          0.0            0.0   \n",
       "4                   0.0        0.0          0.0            0.0   \n",
       "\n",
       "   rv_lv_ratio_gte_1  rv_lv_ratio_lt_1  leftsided_pe  chronic_pe  \\\n",
       "0                0.0               1.0           1.0         0.0   \n",
       "1                0.0               1.0           1.0         0.0   \n",
       "2                0.0               1.0           1.0         0.0   \n",
       "3                0.0               1.0           1.0         0.0   \n",
       "4                0.0               1.0           1.0         0.0   \n",
       "\n",
       "   true_filling_defect_not_pe  rightsided_pe  acute_and_chronic_pe  \\\n",
       "0                         0.0            1.0                   0.0   \n",
       "1                         0.0            1.0                   0.0   \n",
       "2                         0.0            1.0                   0.0   \n",
       "3                         0.0            1.0                   0.0   \n",
       "4                         0.0            1.0                   0.0   \n",
       "\n",
       "   central_pe  indeterminate  \\\n",
       "0         0.0            0.0   \n",
       "1         0.0            0.0   \n",
       "2         0.0            0.0   \n",
       "3         0.0            0.0   \n",
       "4         0.0            0.0   \n",
       "\n",
       "                                          dicom_path  RescaleSlope  \\\n",
       "0  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "1  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "2  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "3  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "4  /mnt/disks/data4/rsna2020/preprocessed/train-j...           1.0   \n",
       "\n",
       "   RescaleIntercept PatientPosition  series_index  num_series   m_i      q_i  \\\n",
       "0           -1024.0             HFS           0.0         124  42.0  0.33871   \n",
       "1           -1024.0             HFS           1.0         124  42.0  0.33871   \n",
       "2           -1024.0             HFS           2.0         124  42.0  0.33871   \n",
       "3           -1024.0             HFS           3.0         124  42.0  0.33871   \n",
       "4           -1024.0             HFS           4.0         124  42.0  0.33871   \n",
       "\n",
       "                                            npy_path  exam_index  \n",
       "0  /mnt/disks/data4/rsna2020/preprocessed/train_l...           0  \n",
       "1  /mnt/disks/data4/rsna2020/preprocessed/train_l...           0  \n",
       "2  /mnt/disks/data4/rsna2020/preprocessed/train_l...           0  \n",
       "3  /mnt/disks/data4/rsna2020/preprocessed/train_l...           0  \n",
       "4  /mnt/disks/data4/rsna2020/preprocessed/train_l...           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set image file paths\n",
    "df_train['npy_path'] = (\n",
    "    train_npy_dir_path + \"/\"\n",
    "    + df_train[col_index] + \".npy\"\n",
    ")\n",
    "print(df_train['npy_path'][0])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1790594, 11)\n",
      "(7279, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>fold1_train</th>\n",
       "      <th>fold1_valid</th>\n",
       "      <th>fold2_train</th>\n",
       "      <th>fold2_valid</th>\n",
       "      <th>fold3_train</th>\n",
       "      <th>fold3_valid</th>\n",
       "      <th>fold4_train</th>\n",
       "      <th>fold4_valid</th>\n",
       "      <th>fold5_train</th>\n",
       "      <th>fold5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6897fa9de148</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>013358b540bb</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0cee26703028</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c28f3d01b14f</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c8fbf1e08ac5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StudyInstanceUID  fold1_train  fold1_valid  fold2_train  fold2_valid  \\\n",
       "0     6897fa9de148            1            0            0            1   \n",
       "1     013358b540bb            0            1            1            0   \n",
       "2     0cee26703028            1            0            1            0   \n",
       "3     c28f3d01b14f            1            0            1            0   \n",
       "4     c8fbf1e08ac5            0            1            1            0   \n",
       "\n",
       "   fold3_train  fold3_valid  fold4_train  fold4_valid  fold5_train  \\\n",
       "0            1            0            1            0            1   \n",
       "1            1            0            1            0            1   \n",
       "2            0            1            1            0            1   \n",
       "3            1            0            1            0            0   \n",
       "4            1            0            1            0            1   \n",
       "\n",
       "   fold5_valid  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data splitting stratified by 3 classes, PE positive, PE negative or indeterminate\n",
    "df_tmp = df_train_exam\n",
    "df_tmp['3class'] = 1 # PE positive\n",
    "df_tmp['3class'][df_tmp['negative_exam_for_pe']==1] = 0 # PE negative\n",
    "df_tmp['3class'][df_tmp['indeterminate']==1] = 2 # indeterminate\n",
    "df_fold_exam = data_split_StratifiedKFold(df_tmp, col_groupby, col_stratified='3class') # apply stratified K-fold\n",
    "df_fold = pd.merge(df_train[[col_groupby]], df_fold_exam, on=col_groupby, how='left')\n",
    "print(df_fold.shape)\n",
    "print(df_fold_exam.shape)\n",
    "df_fold_exam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnWindow(nn.Module): # window setting optimization layer\n",
    "    def __init__(self):\n",
    "        super(nnWindow, self).__init__()\n",
    "        wso = np.array(((40,80),(80,200),(40,400)))/1000\n",
    "        conv_ = nn.Conv2d(1,3, kernel_size=(1, 1))\n",
    "        conv_.weight.data.copy_(torch.tensor([[[[1./wso[0][1]]]],[[[1./wso[1][1]]]],[[[1./wso[2][1]]]]]))\n",
    "        conv_.bias.data.copy_(torch.tensor([0.5 - wso[0][0]/wso[0][1],\n",
    "                                            0.5 - wso[1][0]/wso[1][1],\n",
    "                                            0.5 -wso[2][0]/wso[2][1]]))\n",
    "        self.window = nn.Sequential(\n",
    "            conv_,\n",
    "            nn.Sigmoid(),\n",
    "            nn.InstanceNorm2d(3)\n",
    "        )\n",
    "    def forward(self, input1):\n",
    "        return self.window(input1)\n",
    "        \n",
    "        \n",
    "class CNN_2D(nn.Module):\n",
    "    def __init__(self, num_classes=2, base_model='tf_efficientnet_b0_ns'):\n",
    "        super(CNN_2D, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.mode = 'train'\n",
    "        self.window = nnWindow()\n",
    "        self.base_model = timm.create_model(base_model, pretrained=True, num_classes=10).cuda()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.last_linear = nn.Linear(self.base_model.num_features, num_classes)\n",
    "\n",
    "    def forward(self, input1):\n",
    "        bs, ch, h, w = input1.size()\n",
    "        x = self.window(input1)\n",
    "        x = self.base_model.forward_features(x)\n",
    "        feature = self.avgpool(x).view(bs, -1)\n",
    "        y = self.last_linear(feature)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def feature(self, input1):\n",
    "        bs, ch, h, w = input1.size()\n",
    "        x = self.window(input1)\n",
    "        x = self.base_model.forward_features(x)\n",
    "        feature = self.avgpool(x).view(bs, -1)\n",
    "        y = self.last_linear(feature)\n",
    "\n",
    "        return y, feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define augmentation\n",
    "def get_brightness_contrast(x, brightness_std=0.1, contrast_std=0.1):\n",
    "    alpha = np.clip(1 + np.random.normal()*brightness_std, 0.5, 2)\n",
    "    beta = np.clip(1 + np.random.normal()*contrast_std, 0.5, 2)\n",
    "    mean = x.mean()\n",
    "    x_new = (x- mean[np.newaxis, np.newaxis]) * beta + mean[np.newaxis, np.newaxis]*alpha\n",
    "    return x_new\n",
    "\n",
    "class BrightNessContrastMy(ImageOnlyTransform):\n",
    "    def apply(self, img, **params):\n",
    "        return get_brightness_contrast(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, X_image, X_exam, y, transform=None, mixup=(0, 0), verbose=False):\n",
    "        self.X_image = X_image\n",
    "        self.X_exam = X_exam\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        self.mixup = mixup\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def do_mixup(self, x_image, q, target):\n",
    "        alpha = self.mixup[1]\n",
    "        idx2 = np.random.randint(len(self.X_image))\n",
    "        img_path = self.X_image['npy_path'][idx2]\n",
    "        index_study = self.X_image['exam_index'][idx2]\n",
    "        x_image2 = np.load(img_path).astype(np.float32).reshape([512,512,1])\n",
    "        q2 = self.X_image['q_i'][idx2].astype(np.float16).reshape([1])\n",
    "        M = self.X_exam['RescaleSlope'][index_study]\n",
    "        B = self.X_exam['RescaleIntercept'][index_study]\n",
    "        x_image2 = x_image2 * M + B\n",
    "        target2 = self.y[idx2].astype(np.float16) #.reshape([1])\n",
    "        if self.transform is not None:\n",
    "            x_image2 = self.transform(image=x_image2)['image']\n",
    "\n",
    "        rate = np.random.beta(alpha,alpha)\n",
    "        x_image = x_image*rate + x_image2*(1-rate)\n",
    "        q = q*rate + q2*(1-rate)\n",
    "        target = target*rate + target2*(1-rate)\n",
    "        return x_image, q, target\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.X_image['npy_path'][index]\n",
    "        index_study = self.X_image['exam_index'][index]\n",
    "        x_image = np.load(img_path).astype(np.float32).reshape([512,512,1])\n",
    "        if self.verbose: print(x_image.shape)\n",
    "        q = self.X_image['q_i'][index].astype(np.float16).reshape([1])\n",
    "        M = self.X_exam['RescaleSlope'][index_study]\n",
    "        B = self.X_exam['RescaleIntercept'][index_study]\n",
    "        x_image = x_image * M + B\n",
    "        if self.verbose: print(x_image.mean(), x_image.std())\n",
    "        if self.verbose: print(x_image.shape)\n",
    "        \n",
    "        target = self.y[index].astype(np.float16) #.reshape([1])\n",
    "        if self.transform is not None:\n",
    "            x_image = self.transform(image=x_image)['image']\n",
    "        x_image = (x_image.transpose([2,0,1])/1000).astype(np.float16)\n",
    "        return x_image, target, q\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set class weights\n",
    "# exam-level weigths is equal to the competition metric\n",
    "# (sum of exam-level):image-level = 1:1\n",
    "class_weights = np.array([\n",
    "    0.0736196319, \n",
    "    0.09202453988, \n",
    "    0.1042944785, \n",
    "    0.1042944785, \n",
    "    0.1877300613, \n",
    "    0.06257668712, \n",
    "    0.06257668712,\n",
    "    0.2346625767,\n",
    "    0.0782208589,\n",
    "    1\n",
    "], np.float32) / 2\n",
    "\n",
    "class_weights = torch.from_numpy(class_weights).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training\n",
    "def train(loader, model, optimizer, scheduler, num_step=-1, verbose=10):\n",
    "    if num_step==-1: num_step = len(loader)\n",
    "    loss1_avr = AverageMeter()\n",
    "    criterion1 = nn.BCEWithLogitsLoss(weight=class_weights, reduce=False).cuda()\n",
    "    lastfunc = nn.Sigmoid().cuda()\n",
    "    scaler = torch.cuda.amp.GradScaler() \n",
    "    \n",
    "    # switch to train mode\n",
    "    model .train()\n",
    "\n",
    "    starttime = time.time()\n",
    "    # training\n",
    "    for i, (input1, target, _) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        if i+1>num_step: break\n",
    "        input1 = torch.autograd.Variable(input1.to(device, non_blocking=True)) #.half()\n",
    "        target = torch.autograd.Variable(target.to(device, non_blocking=True)) #.half()\n",
    "        with torch.cuda.amp.autocast(): # mix-precision\n",
    "            output = model(input1)\n",
    "            loss = criterion1(output, target) # calc weighted BCE loss\n",
    "            loss = torch.sum(loss, axis=1)\n",
    "            loss = torch.mean(loss)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        # record loss\n",
    "        loss1_avr.update(loss.data, input1.size(0))\n",
    "        \n",
    "        # display log\n",
    "        if (i+1)%verbose==0 or i+1==num_step:\n",
    "            print(\"Step: {}/{} \".format(i + 1, num_step)\n",
    "                  + \"BCE 1: {:.3f} \".format(loss1_avr.avg.item())\n",
    "                  + \"Sec: {:.1f} \".format(time.time()-starttime)\n",
    "                  )\n",
    "            \n",
    "    return loss1_avr.avg.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define validation\n",
    "def validate(loader, model, verbose=10):\n",
    "    loss1_avr = AverageMeter()\n",
    "    criterion1 = nn.BCEWithLogitsLoss(weight=class_weights, reduce=False).cuda()\n",
    "    lastfunc = nn.Sigmoid().cuda()\n",
    "\n",
    "    # switch to eval mode\n",
    "    model .eval()\n",
    "    \n",
    "    starttime = time.time()\n",
    "    # training\n",
    "    preds = np.zeros([0, NUM_CLASS], np.float32)\n",
    "    for i, (input1, target, _) in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                input1 = input1.to(device, non_blocking=True)\n",
    "                target = target.to(device, non_blocking=True)\n",
    "                output = model(input1)\n",
    "                loss = criterion1(output, target)\n",
    "                loss = torch.sum(loss, axis=1)\n",
    "                loss = torch.mean(loss)\n",
    "                pred = lastfunc(output)\n",
    "\n",
    "        # record loss\n",
    "        loss1_avr.update(loss.data, input1.size(0))\n",
    "        preds = np.concatenate([preds, pred.data.cpu().numpy()])\n",
    "\n",
    "        # display log\n",
    "        if (i+1)%verbose==0 or i+1==len(loader):\n",
    "            print(\"Step: {}/{} \".format(i + 1, len(loader))\n",
    "                  + \"BCE 1: {:.3f} \".format(loss1_avr.avg.item())\n",
    "                  + \"Sec: {:.1f} \".format(time.time()-starttime)\n",
    "                  )\n",
    "        \n",
    "    return loss1_avr.avg.item(), preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = Compose([\n",
    "    ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, interpolation=1, border_mode=0),\n",
    "    RandomCrop(int(512*7/8), int(512*7/8)),\n",
    "    BrightNessContrastMy(p=1),\n",
    "    Cutout(max_h_size=512//8, max_w_size=512//8),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set train log\n",
    "log_columns = ['epoch', 'loss1', 'val_loss1', 'time']\n",
    "for col in col_targets:\n",
    "    log_columns.append(\"val_bce_{}\".format(col))\n",
    "    log_columns.append(\"val_auc_{}\".format(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "Step: 100/512 BCE 1: 0.265 Sec: 152.0 \n",
      "Step: 200/512 BCE 1: 0.255 Sec: 300.0 \n",
      "Step: 300/512 BCE 1: 0.248 Sec: 446.8 \n",
      "Step: 400/512 BCE 1: 0.245 Sec: 597.6 \n",
      "Step: 500/512 BCE 1: 0.241 Sec: 746.6 \n",
      "Step: 512/512 BCE 1: 0.240 Sec: 764.2 \n",
      "Step: 100/449 BCE 1: 0.238 Sec: 133.8 \n",
      "Step: 200/449 BCE 1: 0.220 Sec: 262.4 \n",
      "Step: 300/449 BCE 1: 0.223 Sec: 394.0 \n",
      "Step: 400/449 BCE 1: 0.228 Sec: 526.3 \n",
      "Step: 449/449 BCE 1: 0.225 Sec: 588.4 \n",
      "Epoch: 1/1 BCE 1: 0.240 val BCE 1: 0.225 Sec: 1361.6 \n",
      "val bce negative_exam_for_pe: 0.615 val auc negative_exam_for_pe: 0.635 \n",
      "val bce indeterminate: 0.096 val auc indeterminate: 0.628 \n",
      "val bce chronic_pe: 0.163 val auc chronic_pe: 0.586 \n",
      "val bce acute_and_chronic_pe: 0.080 val auc acute_and_chronic_pe: 0.648 \n",
      "val bce central_pe: 0.191 val auc central_pe: 0.736 \n",
      "val bce leftsided_pe: 0.520 val auc leftsided_pe: 0.636 \n",
      "val bce rightsided_pe: 0.549 val auc rightsided_pe: 0.656 \n",
      "val bce rv_lv_ratio_gte_1: 0.368 val auc rv_lv_ratio_gte_1: 0.661 \n",
      "val bce rv_lv_ratio_lt_1: 0.460 val auc rv_lv_ratio_lt_1: 0.576 \n",
      "val bce pe_present_on_image: 0.145 val auc pe_present_on_image: 0.901 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for fold in range(NUM_FOLD):\n",
    "    starttime = time.time()\n",
    "    if fold+1 not in FOLD_LIST: continue\n",
    "    print(\"fold: {}\".format(fold + 1))\n",
    "    \n",
    "    # reduce validation data to save time\n",
    "    np.random.seed(42)\n",
    "    val_reduce = np.random.rand(np.sum(df_fold['fold{}_valid'.format(fold+1)]==1))<REDUCE_RATE\n",
    "\n",
    "    # build model\n",
    "    if MODEL_NAME=='b0':\n",
    "        base_model = 'tf_efficientnet_b0_ns'\n",
    "    elif MODEL_NAME=='b2':\n",
    "        base_model = 'tf_efficientnet_b2_ns'\n",
    "    model  = CNN_2D(base_model=base_model, num_classes=NUM_CLASS).cuda()\n",
    "    \n",
    "    # train dataset\n",
    "    X_train_image = ri(df_train[df_fold['fold{}_train'.format(fold+1)]==1])\n",
    "    y_train = df_train[col_targets][df_fold['fold{}_train'.format(fold+1)]==1].values\n",
    "    dataset_train = ImageDataset(X_train_image, df_train_exam, y_train, transformations, mixup=(0.5, 0.3))\n",
    "    train_loader = DataLoader(dataset_train,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=multiprocessing.cpu_count(),\n",
    "                              pin_memory=True,\n",
    "                              worker_init_fn=lambda x: np.random.seed(),\n",
    "                              )\n",
    "\n",
    "    # valid dataset\n",
    "    X_valid_image = ri(ri(df_train[df_fold['fold{}_valid'.format(fold+1)]==1].iloc[val_reduce]))\n",
    "    y_valid = df_train[col_targets][df_fold['fold{}_valid'.format(fold+1)]==1].values[val_reduce]\n",
    "    dataset_valid = ImageDataset(X_valid_image, df_train_exam, y_valid)\n",
    "    valid_loader = DataLoader(dataset_valid,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=multiprocessing.cpu_count(),\n",
    "                              pin_memory=True,\n",
    "                              )\n",
    "    \n",
    "    # set optimizer and loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR_RANGE[0])\n",
    "    scheduler = CosineLR(optimizer, step_size_min=LR_RANGE[1], t0=STEP_PER_EPOCH * NUM_CYCLE, tmult=1)\n",
    "    \n",
    "    # set train log dataframe\n",
    "    train_log = pd.DataFrame(columns=log_columns)\n",
    "    \n",
    "    # training\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        loss1 = train(train_loader, model, optimizer, scheduler, num_step=STEP_PER_EPOCH, verbose=100)\n",
    "        val_loss1, val_pred = validate(valid_loader, model, verbose=100)\n",
    "\n",
    "        # save and print log\n",
    "        endtime = time.time() - starttime\n",
    "        print_log = \"Epoch: {}/{} \".format(epoch + 1, NUM_EPOCH)\n",
    "        print_log += \"BCE 1: {:.3f} \".format(loss1)\n",
    "        print_log += \"val BCE 1: {:.3f} \".format(val_loss1)\n",
    "        print_log += \"Sec: {:.1f} \\n\".format(time.time()-starttime)\n",
    "        train_log_epoch = [epoch+1, loss1, val_loss1, endtime]\n",
    "        for i, col in enumerate(col_targets):\n",
    "            score = metrics.log_loss(y_valid[:,i], val_pred[:,i], labels=[0,1])\n",
    "            train_log_epoch.append(score)\n",
    "            print_log += \"val bce {}: {:.3f} \".format(col, score)\n",
    "            \n",
    "            score = metrics.roc_auc_score(y_valid[:,i], val_pred[:,i])\n",
    "            train_log_epoch.append(score)\n",
    "            print_log += \"val auc {}: {:.3f} \\n\".format(col, score)\n",
    "        train_log_epoch = pd.DataFrame([train_log_epoch], columns=log_columns)\n",
    "        train_log = pd.concat([train_log, train_log_epoch])\n",
    "        train_log.to_csv(\"{}/train_log_{}_fold{}.csv\".format(output_dir, MODEL_NAME, fold + 1), index=False)\n",
    "        print(print_log)\n",
    "       \n",
    "        # save weights\n",
    "        if (epoch+1)%NUM_CYCLE==0:\n",
    "            torch.save(model.state_dict(), \"{}/weight_{}_epoch_{}_fold{}.pth\".format(\n",
    "                    output_dir, MODEL_NAME, epoch+1, fold + 1))\n",
    "            torch.save(optimizer.state_dict(), \"{}/optimizer_{}_epoch_{}_fold{}.pth\".format(\n",
    "                    output_dir, MODEL_NAME, epoch+1, fold + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    global start_time\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(loader, model, verbose=10, fold=1):\n",
    "    # make save dir\n",
    "    save_dir = \"{}/features_{}_fold{}\".format(output_dir, MODEL_NAME, fold)\n",
    "    print(save_dir)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    loss1_avr = AverageMeter()\n",
    "\n",
    "    # switch to eval mode\n",
    "    model .eval()\n",
    "\n",
    "    starttime = time.time()\n",
    "    # feature extraction\n",
    "    preds = np.zeros([0, NUM_CLASS], np.float16)\n",
    "    features = np.zeros([0, model.base_model.num_features], np.float16)\n",
    "    exam_index = 0\n",
    "    for i, (input1, _, _) in enumerate(loader):\n",
    "        if DEBUG and exam_index>=20: break\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                input1 = input1.to(device, non_blocking=True)\n",
    "                output, feature = model.feature(input1)\n",
    "\n",
    "        preds = np.concatenate([preds, output.data.cpu().numpy()])\n",
    "        features = np.concatenate([features, feature.data.cpu().numpy()])\n",
    "        while df_train_exam['num_series'][exam_index]<=preds.shape[0]: # concat features by exam level and save\n",
    "            num_series = df_train_exam['num_series'][exam_index]\n",
    "            exam = df_train_exam[col_groupby][exam_index]\n",
    "            if (exam_index+1)%verbose==0:\n",
    "                print(\"{}/{}: exam: {}, len: {}, sec: {:.1f}\".format(\n",
    "                    exam_index+1, len(df_train_exam), exam, num_series, time.time()-starttime))\n",
    "            np.save(\"{}/{}_pred.npy\".format(save_dir, exam), preds[:num_series])\n",
    "            np.save(\"{}/{}_feature.npy\".format(save_dir, exam), features[:num_series])\n",
    "            preds = np.copy(preds[num_series:])\n",
    "            features = np.copy(features[num_series:])\n",
    "            exam_index += 1\n",
    "            if exam_index>=len(df_train_exam): break\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disks/data6/rsna2020/output/features_b0_new_fold1\n",
      "10/7279: exam: 3c5fd9c92057, len: 96, sec: 11.3\n",
      "20/7279: exam: d25e9842c1b3, len: 141, sec: 23.3\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "start_timer()\n",
    "\n",
    "# build model\n",
    "if MODEL_NAME=='b0':\n",
    "    base_model = 'tf_efficientnet_b0_ns'\n",
    "elif MODEL_NAME=='b2':\n",
    "    base_model = 'tf_efficientnet_b2_ns'\n",
    "model  = CNN_2D(base_model=base_model, num_classes=NUM_CLASS).cuda()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.grad = None\n",
    "\n",
    "dataset_valid = ImageDataset(df_train, df_train_exam, df_train[col_targets].values)\n",
    "\n",
    "for fold in range(NUM_FOLD):\n",
    "    if fold+1 not in FOLD_LIST: continue\n",
    "    valid_loader = DataLoader(dataset_valid,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=multiprocessing.cpu_count(),\n",
    "                              pin_memory=True,\n",
    "                              )\n",
    "    \n",
    "    model.load_state_dict(torch.load(\"{}/weight_{}_epoch_{}_fold{}.pth\".format(output_dir, MODEL_NAME, NUM_EPOCH, fold+1)))\n",
    "    extract_feature(valid_loader, model, verbose=10, fold=fold+1)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
